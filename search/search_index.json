{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Extend your pyspark powers with pyspark+","text":"<p>Features \u2728\ufe0f</p> <ul> <li>Wrapper Class!</li> <li>Simple use!</li> <li>Made with A.I. contribution \ud83e\udd16 </li> </ul>"},{"location":"#main-class","title":"Main Class: \ud83d\ude80","text":""},{"location":"examples/functions_01/","title":"Functions Examples!  \ud83d\udc95","text":"In\u00a0[1]: Copied! <pre>pip install pysparkplus\n</pre> pip install pysparkplus <pre>Collecting pysparkplus\n  Downloading pysparkplus-0.0.3-py3-none-any.whl (4.0 kB)\nCollecting pyspark&lt;4.0.0,&gt;=3.4.0 (from pysparkplus)\n  Using cached pyspark-3.4.0-py2.py3-none-any.whl\nCollecting strplus&lt;2.0.0,&gt;=1.0.6 (from pysparkplus)\n  Downloading strplus-1.0.8-py3-none-any.whl (9.8 kB)\nCollecting py4j==0.10.9.7 (from pyspark&lt;4.0.0,&gt;=3.4.0-&gt;pysparkplus)\n  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\nInstalling collected packages: py4j, strplus, pyspark, pysparkplus\nSuccessfully installed py4j-0.10.9.7 pyspark-3.4.0 pysparkplus-0.0.3 strplus-1.0.8\nNote: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"testPysparkPlus\").getOrCreate()\n</pre> from pyspark.sql import SparkSession spark = SparkSession.builder.appName(\"testPysparkPlus\").getOrCreate() <pre>your 131072x1 screen size is bogus. expect trouble\n23/04/23 17:26:48 WARN Utils: Your hostname, DESKTOP-O03M3NM resolves to a loopback address: 127.0.1.1; using 172.17.155.166 instead (on interface eth0)\n23/04/23 17:26:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/04/23 17:26:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n</pre> In\u00a0[3]: Copied! <pre>from pysparkplus.functions import deduplicate\n</pre> from pysparkplus.functions import deduplicate In\u00a0[4]: Copied! <pre>df = spark.createDataFrame([{\"name\":\"Rose\"}, {\"name\":\"Rose\"}])\ndf.show()\n</pre> df = spark.createDataFrame([{\"name\":\"Rose\"}, {\"name\":\"Rose\"}]) df.show() <pre>                                                                                \r</pre> <pre>+----+\n|name|\n+----+\n|Rose|\n|Rose|\n+----+\n\n</pre> In\u00a0[5]: Copied! <pre>df_dedup = deduplicate(df, by_columns=\"name\")\ndf_dedup.show()\n</pre> df_dedup = deduplicate(df, by_columns=\"name\") df_dedup.show() <pre>[Stage 3:============================================&gt;              (6 + 2) / 8]\r</pre> <pre>+----+\n|name|\n+----+\n|Rose|\n+----+\n\n</pre> <pre>                                                                                \r</pre> In\u00a0[6]: Copied! <pre>df_two_cols = spark.createDataFrame([{\"name\":\"Rose\", \"age\":10}, {\"name\":\"Rose\", \"age\":5}])\ndf_two_cols.show()\n</pre> df_two_cols = spark.createDataFrame([{\"name\":\"Rose\", \"age\":10}, {\"name\":\"Rose\", \"age\":5}]) df_two_cols.show() <pre>+---+----+\n|age|name|\n+---+----+\n| 10|Rose|\n|  5|Rose|\n+---+----+\n\n</pre> In\u00a0[7]: Copied! <pre>df_two_dedup = deduplicate(df_two_cols, by_columns=\"name\")\ndf_two_dedup.show()\n</pre> df_two_dedup = deduplicate(df_two_cols, by_columns=\"name\") df_two_dedup.show() <pre>+---+----+\n|age|name|\n+---+----+\n| 10|Rose|\n+---+----+\n\n</pre> In\u00a0[8]: Copied! <pre>df_two_dedup = deduplicate(df_two_cols, by_columns=\"name\", order_by=\"age\")\ndf_two_dedup.show()\n</pre> df_two_dedup = deduplicate(df_two_cols, by_columns=\"name\", order_by=\"age\") df_two_dedup.show() <pre>+---+----+\n|age|name|\n+---+----+\n| 10|Rose|\n+---+----+\n\n</pre> In\u00a0[9]: Copied! <pre>df = spark.createDataFrame([(1, \"a\"), (2, \"b\"), (1, \"a\"), (3, \"c\")], [\"col1\", \"col2\"])\ndf.show()\n</pre> df = spark.createDataFrame([(1, \"a\"), (2, \"b\"), (1, \"a\"), (3, \"c\")], [\"col1\", \"col2\"]) df.show() <pre>+----+----+\n|col1|col2|\n+----+----+\n|   1|   a|\n|   2|   b|\n|   1|   a|\n|   3|   c|\n+----+----+\n\n</pre> In\u00a0[10]: Copied! <pre>df_dedup = deduplicate(df, \"col1\")\ndf_dedup.show()\n</pre> df_dedup = deduplicate(df, \"col1\") df_dedup.show() <pre>+----+----+\n|col1|col2|\n+----+----+\n|   1|   a|\n|   2|   b|\n|   3|   c|\n+----+----+\n\n</pre> In\u00a0[11]: Copied! <pre>df_dedup = deduplicate(df, [\"col1\", \"col2\"], order_by=\"col1\")\ndf_dedup.show()\n</pre> df_dedup = deduplicate(df, [\"col1\", \"col2\"], order_by=\"col1\") df_dedup.show() <pre>+----+----+\n|col1|col2|\n+----+----+\n|   1|   a|\n|   2|   b|\n|   3|   c|\n+----+----+\n\n</pre> In\u00a0[12]: Copied! <pre>### Run project local \ud83d\udcc0\nimport os \nimport sys \nsys.path.insert(0, os.path.abspath(\"../..\"))\nsys.path.insert(0, os.path.abspath(\"..\"))\n</pre> ### Run project local \ud83d\udcc0 import os  import sys  sys.path.insert(0, os.path.abspath(\"../..\")) sys.path.insert(0, os.path.abspath(\"..\"))"},{"location":"examples/functions_01/#functions-examples","title":"Functions Examples!  \ud83d\udc95\u00b6","text":"<p>\ud83d\ude80 Extend your pyspark powers with pyspark+</p>"},{"location":"examples/functions_01/#setup-optional","title":"Setup [Optional]\u00b6","text":"Create a virtualenv \ud83d\udd27  Create a new virtualenv before start this notebook to be able to select it as the kernel, if you want! <ul> <li>Create a new virtualenv.</li> </ul> <pre><code>  pyenv virtualenv 3.9.16 .envPysparkPlus\n  pyenv activate .envPysparkPlus\n  pip install --upgrade pip\n  pip install ipykernel\n</code></pre> <ul> <li><p>Delete the virtualenv.</p> <pre><code>pyenv deactivate .envPysparkPlus\npyenv virtualenv-delete -f .envPysparkPlus\n</code></pre> </li> <li><p>Should return empty</p> <pre><code>pyenv versions | grep .envPysparkPlus\n</code></pre> </li> </ul>"},{"location":"examples/functions_01/#required","title":"Required! \ud83d\udca2\u00b6","text":""},{"location":"examples/functions_01/#simple-deduplicate","title":"Simple deduplicate!\u00b6","text":""},{"location":"pysparkplus/SUMMARY/","title":"package","text":"<ul> <li>functions</li> </ul>"},{"location":"pysparkplus/functions/","title":"Functions","text":""}]}